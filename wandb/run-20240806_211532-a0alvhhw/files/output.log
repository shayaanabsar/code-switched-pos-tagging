
tensor(39.2732, grad_fn=<NegBackward0>)
tensor(32.2058, grad_fn=<NegBackward0>)
tensor(22.6986, grad_fn=<NegBackward0>)
tensor(29.0862, grad_fn=<NegBackward0>)
tensor(20.8726, grad_fn=<NegBackward0>)
Traceback (most recent call last):
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/test.py", line 17, in <module>
    optimizer.step()
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adam.py", line 168, in step
    adam(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adam.py", line 318, in adam
    func(params,
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adam.py", line 393, in _single_tensor_adam
    exp_avg.lerp_(grad, 1 - beta1)
KeyboardInterrupt