Traceback (most recent call last):
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/test.py", line 29, in <module>
    r = t.train(epochs, batch_size, batch_accumulation, input_train, output_train, input_val, output_val)
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/trainer.py", line 67, in train
    loss  += self.pass_batch(batch_size, t_inputs, t_outputs)
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/trainer.py", line 40, in pass_batch
    model_probabilities = self.model(batch_inputs).float()
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/main.py", line 108, in forward
    tokenized  = tokenizer.batch_encode_plus(input, is_split_into_words=True, padding=True, truncation=True, return_tensors='pt').to(device)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 800, in to
    self.data = {k: v.to(device=device) for k, v in self.data.items()}
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 800, in <dictcomp>
    self.data = {k: v.to(device=device) for k, v in self.data.items()}
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/cuda/__init__.py", line 284, in _lazy_init
    raise AssertionError("Torch not compiled with CUDA enabled")
AssertionError: Torch not compiled with CUDA enabled