
0 tensor(2.9761, grad_fn=<DivBackward0>) 0.0001
Traceback (most recent call last):
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/test.py", line 29, in <module>
    r = t.train(epochs, batch_size, batch_accumulation, input_train, output_train, input_val, output_val)
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/trainer.py", line 77, in train
    loss.backward()
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt