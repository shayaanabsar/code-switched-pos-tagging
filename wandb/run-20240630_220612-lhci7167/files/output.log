Traceback (most recent call last):
  File "/root/code-switched-pos-tagging/main.py", line 102, in <module>
    t.train(epochs, batch_size, batch_accumulation, b_input_test, b_output, b_input_val, b_output_val)
  File "/root/code-switched-pos-tagging/trainer.py", line 50, in train
    loss  += self.pass_batch(batch_size, t_inputs, t_outputs)
  File "/root/code-switched-pos-tagging/trainer.py", line 26, in pass_batch
    model_probabilities = self.model(batch_inputs).float()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py", line 185, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py", line 200, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py", line 100, in parallel_apply
    thread.join()
  File "/usr/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt
Traceback (most recent call last):
  File "/root/code-switched-pos-tagging/main.py", line 102, in <module>
    t.train(epochs, batch_size, batch_accumulation, b_input_test, b_output, b_input_val, b_output_val)
  File "/root/code-switched-pos-tagging/trainer.py", line 50, in train
    loss  += self.pass_batch(batch_size, t_inputs, t_outputs)
  File "/root/code-switched-pos-tagging/trainer.py", line 26, in pass_batch
    model_probabilities = self.model(batch_inputs).float()
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py", line 185, in forward
    outputs = self.parallel_apply(replicas, inputs, module_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/data_parallel.py", line 200, in parallel_apply
    return parallel_apply(replicas, inputs, kwargs, self.device_ids[:len(replicas)])
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/parallel_apply.py", line 100, in parallel_apply
    thread.join()
  File "/usr/lib/python3.10/threading.py", line 1096, in join
    self._wait_for_tstate_lock()
  File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
    if lock.acquire(block, timeout):
KeyboardInterrupt