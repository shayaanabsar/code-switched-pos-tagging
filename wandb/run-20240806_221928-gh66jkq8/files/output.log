
0 tensor(2.7774, grad_fn=<NegBackward0>)
1 tensor(2.5751, grad_fn=<NegBackward0>)
2 tensor(2.3538, grad_fn=<NegBackward0>)
3 tensor(2.1533, grad_fn=<NegBackward0>)
4 tensor(2.1075, grad_fn=<NegBackward0>)
5 tensor(1.9354, grad_fn=<NegBackward0>)
6 tensor(1.7236, grad_fn=<NegBackward0>)
7 tensor(1.7502, grad_fn=<NegBackward0>)
8 tensor(1.5670, grad_fn=<NegBackward0>)
9 tensor(1.5073, grad_fn=<NegBackward0>)
10 tensor(1.4308, grad_fn=<NegBackward0>)
11 tensor(1.4101, grad_fn=<NegBackward0>)
12 tensor(1.4102, grad_fn=<NegBackward0>)
13 tensor(1.4319, grad_fn=<NegBackward0>)
14 tensor(1.4266, grad_fn=<NegBackward0>)
15 tensor(1.4015, grad_fn=<NegBackward0>)
16 tensor(1.4193, grad_fn=<NegBackward0>)
17 tensor(1.3533, grad_fn=<NegBackward0>)
18 tensor(1.3679, grad_fn=<NegBackward0>)
19 tensor(1.3340, grad_fn=<NegBackward0>)
20 tensor(1.4003, grad_fn=<NegBackward0>)
21 tensor(1.3408, grad_fn=<NegBackward0>)
22 tensor(1.4050, grad_fn=<NegBackward0>)
23 tensor(1.4213, grad_fn=<NegBackward0>)
24 tensor(1.3376, grad_fn=<NegBackward0>)
25 tensor(1.3932, grad_fn=<NegBackward0>)
26 tensor(1.3822, grad_fn=<NegBackward0>)
27 tensor(1.3436, grad_fn=<NegBackward0>)
28 tensor(1.3367, grad_fn=<NegBackward0>)
29 tensor(1.2872, grad_fn=<NegBackward0>)
30 tensor(1.3223, grad_fn=<NegBackward0>)
31 tensor(1.3550, grad_fn=<NegBackward0>)
32 tensor(1.3400, grad_fn=<NegBackward0>)
33 tensor(1.3826, grad_fn=<NegBackward0>)
34 tensor(1.3119, grad_fn=<NegBackward0>)
35 tensor(1.3942, grad_fn=<NegBackward0>)
36 tensor(1.3793, grad_fn=<NegBackward0>)
37 tensor(1.3545, grad_fn=<NegBackward0>)
38 tensor(1.3873, grad_fn=<NegBackward0>)
39 tensor(1.3483, grad_fn=<NegBackward0>)
40 tensor(1.3440, grad_fn=<NegBackward0>)
41 tensor(1.3948, grad_fn=<NegBackward0>)
42 tensor(1.3910, grad_fn=<NegBackward0>)
43 tensor(1.3772, grad_fn=<NegBackward0>)
44 tensor(1.3938, grad_fn=<NegBackward0>)
45 tensor(1.3854, grad_fn=<NegBackward0>)
46 tensor(1.3883, grad_fn=<NegBackward0>)
47 tensor(1.3038, grad_fn=<NegBackward0>)
48 tensor(1.3683, grad_fn=<NegBackward0>)
49 tensor(1.3696, grad_fn=<NegBackward0>)
50 tensor(1.3176, grad_fn=<NegBackward0>)
51 tensor(1.3584, grad_fn=<NegBackward0>)
52 tensor(1.3605, grad_fn=<NegBackward0>)
53 tensor(1.3478, grad_fn=<NegBackward0>)
54 tensor(1.3285, grad_fn=<NegBackward0>)
55 tensor(1.3127, grad_fn=<NegBackward0>)
56 tensor(1.4006, grad_fn=<NegBackward0>)
Traceback (most recent call last):
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/test.py", line 19, in <module>
    optimizer.step()
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 420, in _single_tensor_adamw
    exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)
KeyboardInterrupt