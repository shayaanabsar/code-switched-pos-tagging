
0 tensor(2.9629, grad_fn=<NegBackward0>)
1 tensor(2.4305, grad_fn=<NegBackward0>)
2 tensor(1.9982, grad_fn=<NegBackward0>)
3 tensor(1.7357, grad_fn=<NegBackward0>)
4 tensor(1.8456, grad_fn=<NegBackward0>)
5 tensor(1.3451, grad_fn=<NegBackward0>)
6 tensor(1.4422, grad_fn=<NegBackward0>)
7 tensor(1.0052, grad_fn=<NegBackward0>)
8 tensor(0.7077, grad_fn=<NegBackward0>)
9 tensor(0.8548, grad_fn=<NegBackward0>)

10 tensor(0.6014, grad_fn=<NegBackward0>)
11 tensor(0.4573, grad_fn=<NegBackward0>)
12 tensor(0.3570, grad_fn=<NegBackward0>)
13 tensor(0.7729, grad_fn=<NegBackward0>)
14 tensor(0.5010, grad_fn=<NegBackward0>)
15 tensor(0.2364, grad_fn=<NegBackward0>)
16 tensor(0.1916, grad_fn=<NegBackward0>)
17 tensor(0.1600, grad_fn=<NegBackward0>)
18 tensor(0.0993, grad_fn=<NegBackward0>)
19 tensor(0.0607, grad_fn=<NegBackward0>)
20 tensor(0.0836, grad_fn=<NegBackward0>)
21 tensor(0.0705, grad_fn=<NegBackward0>)
22 tensor(0.0527, grad_fn=<NegBackward0>)
23 tensor(0.0513, grad_fn=<NegBackward0>)
24 tensor(0.0497, grad_fn=<NegBackward0>)
25 tensor(0.0403, grad_fn=<NegBackward0>)
26 tensor(0.0422, grad_fn=<NegBackward0>)
27 tensor(0.0421, grad_fn=<NegBackward0>)
28 tensor(0.0346, grad_fn=<NegBackward0>)
Traceback (most recent call last):
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/test.py", line 19, in <module>
    optimizer.step()
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 471, in _single_tensor_adamw
    denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)
KeyboardInterrupt