[['cicling', 'er', 'ki', 'halo'], ['amar', 'aar', "chaitali'r", 'common', 'ek', 'friend', 'er', 'saathe', 'dekha', '.']]
[[15, 3, 3, 0], [12, 12, 15, 14, 1, 15, 3, 15, 0, 12]]
torch.Size([2, 10, 19])
0 tensor(2.9148, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
1 tensor(4.5329, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
2 tensor(3.6391, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
3 tensor(2.2711, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
4 tensor(2.6854, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
5 tensor(2.4569, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
6 tensor(2.0746, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
7 tensor(2.0115, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
8 tensor(1.8481, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
9 tensor(1.8250, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
10 tensor(1.9748, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
11 tensor(1.7490, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
12 tensor(1.8298, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
13 tensor(1.9166, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
14 tensor(1.7606, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
15 tensor(1.7267, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
16 tensor(1.8354, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
17 tensor(1.7114, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
18 tensor(1.7094, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
19 tensor(1.7328, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
20 tensor(1.7482, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
21 tensor(1.7537, grad_fn=<NegBackward0>)
torch.Size([2, 10, 19])
22 tensor(1.7007, grad_fn=<NegBackward0>)
Traceback (most recent call last):
  File "/Users/Shayaan/Desktop/code/code-switched-pos-tagging/test.py", line 22, in <module>
    optimizer.step()
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 391, in wrapper
    out = func(*args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/optimizer.py", line 76, in _use_grad
    ret = func(self, *args, **kwargs)
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 188, in step
    adamw(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 340, in adamw
    func(
  File "/Users/Shayaan/.pyenv/versions/3.10.6/lib/python3.10/site-packages/torch/optim/adamw.py", line 419, in _single_tensor_adamw
    exp_avg.lerp_(grad, 1 - beta1)
KeyboardInterrupt
torch.Size([2, 10, 19])